{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f7906f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2b66c",
   "metadata": {},
   "source": [
    "### reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa73f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbd77c012fc4ee0b05cfe994890c7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/Users/timmiakov/Dev/models/Qwen3-Reranker-4B\", padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/Users/timmiakov/Dev/models/Qwen3-Reranker-4B\").to(device).eval()\n",
    "\n",
    "token_false_id = tokenizer.convert_tokens_to_ids(\"no\")\n",
    "token_true_id = tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "max_length = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "331c109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(instructions: List[str]) -> str:\n",
    "    output = \"<Instruct>: {instruction}\\n<Query>: {query}\\n<Document>: {doc}\".format(\n",
    "        instruction=instructions[0], query=instructions[1], doc=instructions[2]\n",
    "    )\n",
    "    return output\n",
    "\n",
    "def process_inputs(pairs: List, prefix_tokens: List[int], suffix_tokens: List[int]) -> Dict:\n",
    "    \n",
    "    tokenizer_max_length = max_length - len(prefix_tokens) - len(suffix_tokens)\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        pairs, padding=True, truncation='longest_first',\n",
    "        return_attention_mask=False, max_length=tokenizer_max_length\n",
    "    )\n",
    "    for i, ele in enumerate(inputs['input_ids']):\n",
    "        inputs['input_ids'][i] = prefix_tokens + ele + suffix_tokens\n",
    "    inputs = tokenizer.pad(inputs, padding=True, return_tensors=\"pt\", max_length=max_length)\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(model.device)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_logits(inputs: Dict, **kwargs) -> List[float]:\n",
    "    batch_scores = model(**inputs).logits[:, -1, :]\n",
    "    true_vector = batch_scores[:, token_true_id]\n",
    "    false_vector = batch_scores[:, token_false_id]\n",
    "    batch_scores = torch.stack([false_vector, true_vector], dim=1)\n",
    "    batch_scores = torch.nn.functional.log_softmax(batch_scores, dim=1)\n",
    "    scores = batch_scores[:, 1].exp().tolist()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f210f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke(prefix: str, suffix: str, insturction: str, query: str, documents: List[str]):\n",
    "    \n",
    "    assert isinstance(insturction, str) == True\n",
    "    assert isinstance(query, str) == True\n",
    "    \n",
    "    prefix_tokens = tokenizer.encode(prefix, add_special_tokens=False)\n",
    "    suffix_tokens = tokenizer.encode(suffix, add_special_tokens=False)\n",
    "\n",
    "    pairs = list(map(format_instruction, list(itertools.product([insturction], [query], documents))))\n",
    "\n",
    "    inputs = process_inputs(pairs, prefix_tokens, suffix_tokens)\n",
    "    \n",
    "    return compute_logits(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca62526a",
   "metadata": {},
   "source": [
    "### test queires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9961a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/processed/webqsp_test_results_resolved.json\", 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "with open(\"results/processed/webqsp_test_results_PROMPTS.json\", 'r') as f:\n",
    "    test_prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f9dcc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 47\n",
    "test_q = test_data[idx]\n",
    "test_q\n",
    "nodes = [n[1] for n in test_q['retrieved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "00fc1c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'WebQTest-63',\n",
       " 'retrieved': [['m.0rmg', 'andrew johnson administration', 0.3487710654735565],\n",
       "  ['m.03mpk', 'hannibal hamlin', 0.20501472055912018],\n",
       "  ['m.04gc2', 'defense attourney', 0.15570005774497986],\n",
       "  ['m.0fj9f', 'politition', 0.15130020678043365],\n",
       "  ['m.016fc2', 'statesman\"@e', 0.13650622963905334]],\n",
       " 'answers': [['m.03mpk', 'hannibal hamlin'],\n",
       "  ['m.0rmg', 'andrew johnson administration']],\n",
       " 'question': 'who was vp for lincoln'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bf2f7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = test_prompts[test_q['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f4c58dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abraham lincon --> government.us_vice_president.to_president --> andrew johnson administration',\n",
       " 'andrew johnson administration --> government.us_president.vice_president --> abraham lincon',\n",
       " 'abraham lincon --> government.us_vice_president.to_president --> hannibal hamlin',\n",
       " 'hannibal hamlin --> government.us_president.vice_president --> abraham lincon',\n",
       " 'defense attourney --> people.person.profession --> abraham lincon',\n",
       " 'abraham lincon --> media_common.dedication.dedicated_to --> m.04tl_wn --> media_common.dedicator.dedications --> us legislative branch --> government.government_office_or_title.governmental_body_if_any --> united states congressperson --> base.onephylogeny.type_of_thing.things_of_this_type --> politition',\n",
       " 'politition --> people.person.profession --> abraham lincon',\n",
       " 'abraham lincon --> media_common.dedication.dedicated_to --> m.04tl_wn --> media_common.dedicator.dedications --> us legislative branch --> government.government_office_or_title.governmental_body_if_any --> united states congressperson --> base.onephylogeny.type_of_thing.things_of_this_type --> politition --> people.profession.specialization_of --> statesman\"@e',\n",
       " 'statesman\"@e --> people.person.profession --> abraham lincon']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf1cf3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_test_graph = []\n",
    "for st in test_graph:\n",
    "    ents = st.split(' --> ')\n",
    "    new_str = ents[2] + ' --> ' + ents[1] + ' --> ' + ents[0] \n",
    "    reverse_test_graph.append(new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cdac8e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['andrew johnson administration --> government.us_vice_president.to_president --> abraham lincon',\n",
       " 'abraham lincon --> government.us_president.vice_president --> andrew johnson administration',\n",
       " 'hannibal hamlin --> government.us_vice_president.to_president --> abraham lincon',\n",
       " 'abraham lincon --> government.us_president.vice_president --> hannibal hamlin',\n",
       " 'abraham lincon --> people.person.profession --> defense attourney',\n",
       " 'm.04tl_wn --> media_common.dedication.dedicated_to --> abraham lincon',\n",
       " 'abraham lincon --> people.person.profession --> politition',\n",
       " 'm.04tl_wn --> media_common.dedication.dedicated_to --> abraham lincon',\n",
       " 'abraham lincon --> people.person.profession --> statesman\"@e']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_test_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5578ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \\\"yes\\\" or \\\"no\\\".<|im_end|>\\n<|im_start|>user\\n\"\n",
    "suffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "\n",
    "instruction = \"\"\"The graph of knowledge is given in the format:\n",
    "Entity 1 (vertex) -> entity relation (edge) -> Entity 2 (vertex)\n",
    "Having this graph and a query for it, choose the Entities that are relevant answers to that query.\n",
    "Graph:\\n\"\"\"\n",
    "instruction += '\\n'.join(reverse_test_graph)\n",
    "\n",
    "queries = test_q['question']\n",
    "\n",
    "documents = [r[1] for r in test_q['retrieved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "438e70ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/gnnrag/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scores = invoke(\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    insturction=instruction,\n",
    "    query=queries,\n",
    "    documents=documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5349dc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['andrew johnson administration',\n",
       " 'hannibal hamlin',\n",
       " 'defense attourney',\n",
       " 'politition',\n",
       " 'statesman\"@e']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3b75f5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09347117692232132,\n",
       " 0.9863868355751038,\n",
       " 0.003919102717190981,\n",
       " 0.0025081755593419075,\n",
       " 0.0012620736379176378]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4d3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
